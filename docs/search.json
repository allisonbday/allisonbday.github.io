[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "allisonbday.github.io",
    "section": "",
    "text": "Pandas Groupby & Aggregations\n\n\n\n\n\n\n\nPython\n\n\nPandas\n\n\nCode Snippets\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\nAllison Day\n\n\n\n\n\n\n  \n\n\n\n\nANSI Colored Text in Terminal/Outputs\n\n\n\n\n\n\n\nPython\n\n\nJupyter Notebooks\n\n\nCode Snippets\n\n\n\n\nCredit goes to this StackOverflow thread\n\n\n\n\n\n\nFeb 28, 2023\n\n\nAllison Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with Nested JSONs\n\n\n\n\n\n\n\nAPIs\n\n\nJSON\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2022\n\n\nAllison Day\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "jobs/doterra.html",
    "href": "jobs/doterra.html",
    "title": "Allison Day",
    "section": "",
    "text": "SELECT u.user_id, SUM(o.amt) AS total\nFROM user u\nLEFT JOIN order_header o ON u.user_id = o.user_id\nGROUP BY user_id;\nReturns a table that looks like this: | user_id | total | |———|——–| | 1 | 52 | | 2 | 169 | | 3 | null |\nThe users who haven’t spent money will have a null in the total column. It would be interesting to sort desc or filter to only orders of that week, or maybe to market to find which is the most productive. Pretty basic but opens the door to interesting insights.\n\n\n\nSELECT u.*\nFROM user u\nWHERE NOT EXISTS (SELECT 1 FROM order_header o WHERE o.user_id = u.user_id);\nreturns a table that looks like this: | user_id | name | market | |———|———|——–| | 3 | Ruby | North |\nI chose WHERE NOT EXISTS over WHERE o.user_ID IS NULL because I think exists future proofs the query more since we are joining tables and may want to add more constraints in the future.\n\n\n\nCREATE INDEX idx_market\nON user (market);\n\nCREATE INDEX idx_order_date\nON order_header (order_date);\nIf I had millions of rows, I would want to make an index of the different markets so that I can easily filter by a specific market.\nMy logic for the order table falls along those same lines. When I’m working with time data I often filter by date and creating an index would speed up the WHERE statement.\n\n\n\n\nThis is a snippet of code from my internship that I’m particularly proud of. I had to go through a dataset of points, get the overlapping ones and then rank as they rose (lowest was 1, highest was n). But if a height was missing then it needed to skip that height (start at 2). Speed was the most important factor. This code needed to comb through over thousands of points every few seconds.\n# python using pandas\ncenters[\"position\"] = centers.groupby([\"x\", \"y\"]).ngroup()\ncenters[\"heightlist\"] = centers.groupby(\"position\")[\"z\"].transform(\"count\")\navg_level = ceil(centers[\"heightlist\"].mean())\n\nfor position in centers[\"position\"].unique():\n    pos = centers.loc[(centers[\"position\"] == position)]\n    pos.sort_values(by=[\"z\"], ascending=True, inplace=True)\n\n    if pos[\"heightlist\"].min() < avg_level:\n        high = avg_level\n    else:\n        high = pos[\"heightlist\"].min()\n\n    levels = []\n    for i in range(len(pos)):\n        levels.append(high - i)\n\n    centers.loc[(centers[\"position\"] == position), \"level\"] = levels\nLine 1 centers[\"position\"] = centers.groupby([\"x\", \"y\"]).ngroup() Creates a new column named [position] and has a unique id for each unique (x,y). This is very helpful to help us filter each position later.\nLine 2 centers[\"heightlist\"] = centers.groupby(\"position\")[\"z\"].transform(\"count\") Groups by position, and counts the number of unique z values are in that position.\nLine 3 avg_level = ceil(centers[\"heightlist\"].mean()) The average heightlist for the whole dataset\nLine 4 for position in centers[\"position\"].unique(): This line ittorated through the centers.csv to find each unique position (x,y) for filtering.\nLine 5 pos = centers.loc[(centers[\"position\"] == position)] Creates a filtered dataset named pos containing only those with the same position as the loop.\nLine 6 pos.sort_values(by=[\"z\"], ascending=True, inplace=True) Sorts all of the values by their z in ascending order so that when we rank it will be from lowest to highest (1, …, n). Decided to do it inplace so that we don’t have to redefine pos again, and because we’re not losing any data.\nLines 7-10\nif pos[\"heightlist\"].min() < avg_level:\n    high = avg_level\nelse:\n    high = pos[\"heightlist\"].min()\nEven though pos should have the same heightlist for every position (since it was generated using position), I decided to use the .min() aggrigation anyway because we’re checking if it’s above the average_level. If it is above or equal to average level then it will just use the number of heights. However, if it is below average then it is missing heights and needs to start at a different number, which will be calculated from the average (so high = average).\nLines 11-13\nlevels = []\nfor i in range(len(pos)):\n    levels.append(high - i)\nlevels is a list of all of the heights. As the loop ittorates, i will become bigger and as we append make levels count down. Usually high matches the count of rows, so levels counts down to one [5, ..., 1]. However, if it was determined to not have enough levels it will only count down from average [5, ..., 2].\nLine 14 centers.loc[(centers[\"position\"] == position), \"level\"] = levels This maps the correct height to the centers.csv using the levels list using .loc. It filters down to all the rows with the same position, then defines the column [level] to match the list levels. The filtered centers.csv and the levels list must be the same length or else there will be errors, but because we calculated the levels list using the length of the filtered dataframe they should always match."
  },
  {
    "objectID": "posts/nested_jsons/Nested_JSONs.html",
    "href": "posts/nested_jsons/Nested_JSONs.html",
    "title": "Working with Nested JSONs",
    "section": "",
    "text": "Imports\n# this is code-fold\nimport pandas as pd\nimport json\n\njson_raw = \"code/json_example.json\"\nwith open(json_raw) as json_data:\n    json_example = json.load(json_data)\n\n\nLets say pulled an API and it gave you this json:\n{\n    \"Total\": 1,\n    \"Page\": 1,\n    \"Products\": [\n        {\n            \"ID\": 12345,\n            \"SKU\": \"Clownfish\",\n            \"Name\": \"Nemo\",\n            \"Suppliers\": [\n                {\n                    \"SupplierID\": \"67891\",\n                    \"SupplierName\": \"Little Fish Inc\",\n                    \"Cost\": 5.99\n                },\n                {\n                    \"SupplierID\": \"24601\",\n                    \"SupplierName\": \"Large Pond Co\",\n                    \"Cost\": 5.59\n                }\n            ],\n            \"PriceTiers\": {\n                \"Public Retail Price\": 24.99,\n                \"Employee Price\": 6.0\n            }\n        }\n    ]\n}\n\nBasic\n\ndf = pd.json_normalize(\n    json_example, \n    record_path=[\"Products\"],\n    errors=\"ignore\",\n    )\n\nprint(df.to_markdown())\n\n|    |    ID | SKU       | Name   | Suppliers                                                                                                                                          |   PriceTiers.Public Retail Price |   PriceTiers.Employee Price |\n|---:|------:|:----------|:-------|:---------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------:|----------------------------:|\n|  0 | 12345 | Clownfish | Nemo   | [{'SupplierID': '67891', 'SupplierName': 'Little Fish Inc', 'Cost': 5.99}, {'SupplierID': '24601', 'SupplierName': 'Large Pond Co', 'Cost': 5.59}] |                            24.99 |                           6 |\n\n\n\n\nBy Suppliers\n\ndf = pd.json_normalize(\n    json_example,\n    record_path=[\"Products\", \"Suppliers\"],\n    meta=[\n        [\"Products\"],\n    ],\n    errors=\"ignore\",\n)\n\nprint(df.to_markdown())\n\n|    |   SupplierID | SupplierName    |   Cost | Products                                                                                                                                                                                                                                                                                |\n|---:|-------------:|:----------------|-------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n|  0 |        67891 | Little Fish Inc |   5.99 | {'ID': 12345, 'SKU': 'Clownfish', 'Name': 'Nemo', 'Suppliers': [{'SupplierID': '67891', 'SupplierName': 'Little Fish Inc', 'Cost': 5.99}, {'SupplierID': '24601', 'SupplierName': 'Large Pond Co', 'Cost': 5.59}], 'PriceTiers': {'Public Retail Price': 24.99, 'Employee Price': 6.0}} |\n|  1 |        24601 | Large Pond Co   |   5.59 | {'ID': 12345, 'SKU': 'Clownfish', 'Name': 'Nemo', 'Suppliers': [{'SupplierID': '67891', 'SupplierName': 'Little Fish Inc', 'Cost': 5.99}, {'SupplierID': '24601', 'SupplierName': 'Large Pond Co', 'Cost': 5.59}], 'PriceTiers': {'Public Retail Price': 24.99, 'Employee Price': 6.0}} |\n\n\n\n\nGet Product Columns\n\ndf = pd.json_normalize(\n    json_example,\n    record_path=[\"Products\", \"Suppliers\"],\n    meta=[\n        [\"Products\", \"ID\"],\n        [\"Products\", \"SKU\"],\n        [\"Products\", \"Name\"],\n        [\"Products\", \"PriceTiers\"], \n    ],\n    errors=\"ignore\",\n)\n\nprint(df.to_markdown())\n\n|    |   SupplierID | SupplierName    |   Cost |   Products.ID | Products.SKU   | Products.Name   | Products.PriceTiers                                   |\n|---:|-------------:|:----------------|-------:|--------------:|:---------------|:----------------|:------------------------------------------------------|\n|  0 |        67891 | Little Fish Inc |   5.99 |         12345 | Clownfish      | Nemo            | {'Public Retail Price': 24.99, 'Employee Price': 6.0} |\n|  1 |        24601 | Large Pond Co   |   5.59 |         12345 | Clownfish      | Nemo            | {'Public Retail Price': 24.99, 'Employee Price': 6.0} |\n\n\n\n\nInclude all of the sub dictionary columns too\n\ndf = pd.json_normalize(\n    json_example,\n    record_path=[\"Products\", \"Suppliers\"],\n    meta=[\n        [\"Products\", \"ID\"],\n        [\"Products\", \"SKU\"],\n        [\"Products\", \"Name\"],\n        [\"Products\", \"PriceTiers\", \"Public Retail Price\"], \n        [\"Products\", \"PriceTiers\", \"Employee Price\"]\n    ],\n    errors=\"ignore\",\n)\n\nprint(df.to_markdown())\n\n|    |   SupplierID | SupplierName    |   Cost |   Products.ID | Products.SKU   | Products.Name   |   Products.PriceTiers.Public Retail Price |   Products.PriceTiers.Employee Price |\n|---:|-------------:|:----------------|-------:|--------------:|:---------------|:----------------|------------------------------------------:|-------------------------------------:|\n|  0 |        67891 | Little Fish Inc |   5.99 |         12345 | Clownfish      | Nemo            |                                     24.99 |                                    6 |\n|  1 |        24601 | Large Pond Co   |   5.59 |         12345 | Clownfish      | Nemo            |                                     24.99 |                                    6 |"
  },
  {
    "objectID": "posts/colored_text/print_colored_text.html",
    "href": "posts/colored_text/print_colored_text.html",
    "title": "ANSI Colored Text in Terminal/Outputs",
    "section": "",
    "text": "needs to be inside the \"\" when printing\ncustomization starts with a \\033[ split by ; and ends with m\nprint statement ends with \\033[0m"
  },
  {
    "objectID": "posts/colored_text/print_colored_text.html#effects",
    "href": "posts/colored_text/print_colored_text.html#effects",
    "title": "ANSI Colored Text in Terminal/Outputs",
    "section": "Effects",
    "text": "Effects\n\nprint(f\"\\033[0m 0 = normal \\033[0m\")\nprint(f\"\\033[1m 1 = bold \\033[0m\")\nprint(f\"\\033[3m 3 = italic \\033[0m\")\nprint(f\"\\033[4m 4 = underline \\033[0m\")\nprint(f\"\\033[9m 9 = crossed-out \\033[0m\")"
  },
  {
    "objectID": "posts/colored_text/print_colored_text.html#text-color",
    "href": "posts/colored_text/print_colored_text.html#text-color",
    "title": "ANSI Colored Text in Terminal/Outputs",
    "section": "Text Color",
    "text": "Text Color\n\nprint(f\"\\033[0m 0 = normal \\033[0m\")\nprint(f\"\\033[30m 30 = white \\033[0m\")\nprint(f\"\\033[31m 31 = red \\033[0m\")\nprint(f\"\\033[32m 32 = green \\033[0m\")\nprint(f\"\\033[33m 33 = yellow \\033[0m\")\nprint(f\"\\033[34m 34 = blue \\033[0m\")\nprint(f\"\\033[35m 35 = pink \\033[0m\")\nprint(f\"\\033[36m 36 = teal \\033[0m\")\nprint(f\"\\033[37m 37 = gray \\033[0m\")"
  },
  {
    "objectID": "posts/colored_text/print_colored_text.html#background-color",
    "href": "posts/colored_text/print_colored_text.html#background-color",
    "title": "ANSI Colored Text in Terminal/Outputs",
    "section": "Background Color",
    "text": "Background Color\n\nprint(f\"\\033[49m 49 = normal \\033[0m\")\nprint(f\"\\033[40m 40 = white \\033[0m\")\nprint(f\"\\033[41m 41 = red \\033[0m\")\nprint(f\"\\033[42m 42 = green \\033[0m\")\nprint(f\"\\033[43m 43 = yellow \\033[0m\")\nprint(f\"\\033[44m 44 = blue \\033[0m\")\nprint(f\"\\033[45m 45 = pink \\033[0m\")\nprint(f\"\\033[46m 46 = teal \\033[0m\")\nprint(f\"\\033[47m 47 = gray \\033[0m\")"
  },
  {
    "objectID": "posts/colored_text/print_colored_text.html#combining",
    "href": "posts/colored_text/print_colored_text.html#combining",
    "title": "ANSI Colored Text in Terminal/Outputs",
    "section": "Combining",
    "text": "Combining\n\nprint(f\"\\033[4;31;42m; 42 = underlined red on green \\033[0m\")"
  },
  {
    "objectID": "posts/colored_text/print_colored_text.html#simple---8-colors",
    "href": "posts/colored_text/print_colored_text.html#simple---8-colors",
    "title": "ANSI Colored Text in Terminal/Outputs",
    "section": "Simple - 8 colors",
    "text": "Simple - 8 colors\n\nEffects\n\nprint(f\"\\033[0m 0 = normal \\033[0m\")\nprint(f\"\\033[1m 1 = bold \\033[0m\")\nprint(f\"\\033[3m 3 = italic \\033[0m\")\nprint(f\"\\033[4m 4 = underline \\033[0m\")\nprint(f\"\\033[9m 9 = crossed-out \\033[0m\")\n\n\n\nText Color\n\nprint(f\"\\033[0m 0 = normal \\033[0m\")\nprint(f\"\\033[30m 30 = white \\033[0m\")\nprint(f\"\\033[31m 31 = red \\033[0m\")\nprint(f\"\\033[32m 32 = green \\033[0m\")\nprint(f\"\\033[33m 33 = yellow \\033[0m\")\nprint(f\"\\033[34m 34 = blue \\033[0m\")\nprint(f\"\\033[35m 35 = pink \\033[0m\")\nprint(f\"\\033[36m 36 = teal \\033[0m\")\nprint(f\"\\033[37m 37 = gray \\033[0m\")\n\n\n\nBackground Color\n\nprint(f\"\\033[49m 49 = normal \\033[0m\")\nprint(f\"\\033[40m 40 = white \\033[0m\")\nprint(f\"\\033[41m 41 = red \\033[0m\")\nprint(f\"\\033[42m 42 = green \\033[0m\")\nprint(f\"\\033[43m 43 = yellow \\033[0m\")\nprint(f\"\\033[44m 44 = blue \\033[0m\")\nprint(f\"\\033[45m 45 = pink \\033[0m\")\nprint(f\"\\033[46m 46 = teal \\033[0m\")\nprint(f\"\\033[47m 47 = gray \\033[0m\")\n\n\n\nCombining\n\nprint(f\"\\033[4;31;42m; 42 = underlined red text on green background \\033[0m\")\n\n\n# create text + background combo table\nfor bg in range(40, 48):\n    string = \"\"\n    for txt in range(30, 38):\n        string += f\"\\033[{txt};{bg}m {txt};{bg} \\033[0m\"\n    print(string)"
  },
  {
    "objectID": "posts/colored_text/print_colored_text.html#more-advanced---256-colors-beyond",
    "href": "posts/colored_text/print_colored_text.html#more-advanced---256-colors-beyond",
    "title": "ANSI Colored Text in Terminal/Outputs",
    "section": "More Advanced - 256 Colors & Beyond!",
    "text": "More Advanced - 256 Colors & Beyond!\n\n256 colors\n * Note: only change the last number\nText\n\n# text 1st number is 38 (because that's the 'custom color' number); \nprint(\"\\033[38;5;141m purple text 141, \\033[0m\")\n\nBackground\n\n# background 1st number is 48 (background 'custom color' number)\nprint(\"\\033[48;5;154m green background 154 \\033[0m\")\n\n\n\nRGB\nOr you can use rgb values to create your own custom colors!\nText\n\n# \\033[38;2;<r>;<g>;<b>m\nprint(\"\\033[38;2;5;42;177m CUSTOM! dark blue background \\033[0m\")\n\nBackground\n\n# \\033[48;2;<r>;<g>;<b>m\nprint(\"\\033[48;2;229;242;147m CUSTOM! light yellow/green background \\033[0m\")"
  },
  {
    "objectID": "posts/colored_text/print_colored_text.html#more-advanced---256-colors-rgb",
    "href": "posts/colored_text/print_colored_text.html#more-advanced---256-colors-rgb",
    "title": "ANSI Colored Text in Terminal/Outputs",
    "section": "More Advanced - 256 Colors & RGB!",
    "text": "More Advanced - 256 Colors & RGB!\n\n256 colors\n * Note: only change the last number\nText\n\n# text 1st number is 38 (because that's the 'custom color' number); \nprint(\"\\033[38;5;141m purple text 141, \\033[0m\")\n\nBackground\n\n# background 1st number is 48 (background 'custom color' number)\nprint(\"\\033[48;5;154m green background 154 \\033[0m\")\n\n\n\nRGB\nOr you can use rgb values to create your own custom colors!\n\nText\n\n# \\033[38;2;<r>;<g>;<b>m\nprint(\"\\033[38;2;5;42;177m CUSTOM! dark blue background \\033[0m\")\n\nBackground\n\n# \\033[48;2;<r>;<g>;<b>m\nprint(\"\\033[48;2;229;242;147m CUSTOM! light yellow/green background \\033[0m\")"
  },
  {
    "objectID": "posts/groupby_snippets/groupby_snippets.html",
    "href": "posts/groupby_snippets/groupby_snippets.html",
    "title": "Pandas Groupby & Aggregations",
    "section": "",
    "text": "# IMPORTS\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns # get dataset\n\n# Create Random DF\ndf = sns.load_dataset('flights')\ndf\n\n\n\n\n\n  \n    \n      \n      year\n      month\n      passengers\n    \n  \n  \n    \n      0\n      1949\n      Jan\n      112\n    \n    \n      1\n      1949\n      Feb\n      118\n    \n    \n      2\n      1949\n      Mar\n      132\n    \n    \n      3\n      1949\n      Apr\n      129\n    \n    \n      4\n      1949\n      May\n      121\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      139\n      1960\n      Aug\n      606\n    \n    \n      140\n      1960\n      Sep\n      508\n    \n    \n      141\n      1960\n      Oct\n      461\n    \n    \n      142\n      1960\n      Nov\n      390\n    \n    \n      143\n      1960\n      Dec\n      432\n    \n  \n\n144 rows × 3 columns"
  },
  {
    "objectID": "posts/groupby_snippets/groupby_snippets.html#agg-function",
    "href": "posts/groupby_snippets/groupby_snippets.html#agg-function",
    "title": "Pandas Groupby & Aggregations",
    "section": ".agg function",
    "text": ".agg function\n\ndf.groupby('year')[\"passengers\"].agg(\"mean\")\n\nyear\n1949    126.666667\n1950    139.666667\n1951    170.166667\n1952    197.000000\n1953    225.000000\n1954    238.916667\n1955    284.000000\n1956    328.250000\n1957    368.416667\n1958    381.000000\n1959    428.333333\n1960    476.166667\nName: passengers, dtype: float64\n\n\nlets you pass in a list of functions\n\ndf.groupby('year')[\"passengers\"].agg([\"mean\", \"max\", \"rank\"])\n\n\n\n\n\n  \n    \n      \n      mean\n      max\n      rank\n    \n  \n  \n    \n      0\n      NaN\n      NaN\n      2.0\n    \n    \n      1\n      NaN\n      NaN\n      3.5\n    \n    \n      2\n      NaN\n      NaN\n      8.0\n    \n    \n      3\n      NaN\n      NaN\n      7.0\n    \n    \n      4\n      NaN\n      NaN\n      6.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1956\n      328.250000\n      413.0\n      NaN\n    \n    \n      1957\n      368.416667\n      467.0\n      NaN\n    \n    \n      1958\n      381.000000\n      505.0\n      NaN\n    \n    \n      1959\n      428.333333\n      559.0\n      NaN\n    \n    \n      1960\n      476.166667\n      622.0\n      NaN\n    \n  \n\n156 rows × 3 columns\n\n\n\nand assign functions to specific columns\n\ndf.groupby('year').agg({\"passengers\": [\"mean\", \"max\", \"rank\"], \"month\": \"first\"})\n\n\n\n\n\n  \n    \n      \n      passengers\n      month\n    \n    \n      \n      mean\n      max\n      rank\n      first\n    \n  \n  \n    \n      0\n      NaN\n      NaN\n      2.0\n      NaN\n    \n    \n      1\n      NaN\n      NaN\n      3.5\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n      8.0\n      NaN\n    \n    \n      3\n      NaN\n      NaN\n      7.0\n      NaN\n    \n    \n      4\n      NaN\n      NaN\n      6.0\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1956\n      328.250000\n      413.0\n      NaN\n      Jan\n    \n    \n      1957\n      368.416667\n      467.0\n      NaN\n      Jan\n    \n    \n      1958\n      381.000000\n      505.0\n      NaN\n      Jan\n    \n    \n      1959\n      428.333333\n      559.0\n      NaN\n      Jan\n    \n    \n      1960\n      476.166667\n      622.0\n      NaN\n      Jan\n    \n  \n\n156 rows × 4 columns"
  },
  {
    "objectID": "posts/groupby_snippets/groupby_snippets.html#dealing-with-multiindex-headers",
    "href": "posts/groupby_snippets/groupby_snippets.html#dealing-with-multiindex-headers",
    "title": "Pandas Groupby & Aggregations",
    "section": "dealing with multiindex headers",
    "text": "dealing with multiindex headers\nthis article is the best at explaining 🔗link\n\n# multi index header\nmulti = df.groupby(\"year\").agg({\"passengers\": [np.min, np.mean, np.max]})\n\nprint(multi.columns)\ndisplay(multi)\n\nMultiIndex([('passengers', 'amin'),\n            ('passengers', 'mean'),\n            ('passengers', 'amax')],\n           )\n\n\n\n\n\n\n  \n    \n      \n      passengers\n    \n    \n      \n      amin\n      mean\n      amax\n    \n    \n      year\n      \n      \n      \n    \n  \n  \n    \n      1949\n      104\n      126.666667\n      148\n    \n    \n      1950\n      114\n      139.666667\n      170\n    \n    \n      1951\n      145\n      170.166667\n      199\n    \n    \n      1952\n      171\n      197.000000\n      242\n    \n    \n      1953\n      180\n      225.000000\n      272\n    \n    \n      1954\n      188\n      238.916667\n      302\n    \n    \n      1955\n      233\n      284.000000\n      364\n    \n    \n      1956\n      271\n      328.250000\n      413\n    \n    \n      1957\n      301\n      368.416667\n      467\n    \n    \n      1958\n      310\n      381.000000\n      505\n    \n    \n      1959\n      342\n      428.333333\n      559\n    \n    \n      1960\n      390\n      476.166667\n      622\n    \n  \n\n\n\n\nNotice how they columns seem to be layered, and the multi.columns is giving a list of tuples instead of the normal list of strings. To get rid of this there are a few ways - including the function .to_flat_index(). But my favorite way is to join the names with a underscore (_).\n\nmulti.columns = ['_'.join(col) for col in multi.columns.values]\nprint(multi.columns)\ndisplay(multi)\n\nIndex(['passengers_amin', 'passengers_mean', 'passengers_amax'], dtype='object')\n\n\n\n\n\n\n  \n    \n      \n      passengers_amin\n      passengers_mean\n      passengers_amax\n    \n    \n      year\n      \n      \n      \n    \n  \n  \n    \n      1949\n      104\n      126.666667\n      148\n    \n    \n      1950\n      114\n      139.666667\n      170\n    \n    \n      1951\n      145\n      170.166667\n      199\n    \n    \n      1952\n      171\n      197.000000\n      242\n    \n    \n      1953\n      180\n      225.000000\n      272\n    \n    \n      1954\n      188\n      238.916667\n      302\n    \n    \n      1955\n      233\n      284.000000\n      364\n    \n    \n      1956\n      271\n      328.250000\n      413\n    \n    \n      1957\n      301\n      368.416667\n      467\n    \n    \n      1958\n      310\n      381.000000\n      505\n    \n    \n      1959\n      342\n      428.333333\n      559\n    \n    \n      1960\n      390\n      476.166667\n      622"
  }
]